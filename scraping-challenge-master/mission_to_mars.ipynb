{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "# *                                                                                               * #\n",
    "#@ * * * * * * * * * * * * * * * * * / Mission to Mars: Notebook / * * * * * * * * * * * * * * * * *@\n",
    "# *                                                                                               * #\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -@\n",
    "#@ * * * * * * * * * * * * * * * * / Dependencies + Initialization / * * * * * * * * * * * * * * * * @\n",
    "#@ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import os\n",
    "import imgkit\n",
    "import subprocess\n",
    "\n",
    "def init_splinter():\n",
    "    '''\n",
    "        init_splinter() initializes and returns an automated Chrome web browser for us to use for\n",
    "    scraping.\n",
    "    '''\n",
    "    print('Initizalizing Splinter Browser...\\n')\n",
    "    time.sleep(2)\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    return browser\n",
    "\n",
    "def simmer_soup(browser):\n",
    "    '''\n",
    "        simmer_soup() receives the Splinter browser and returns the current page's parsed html as\n",
    "    \"Soup\".\n",
    "    '''\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    return html, soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "# *                                                                                               * #\n",
    "#@ * * * * * * * * * * * * * * * * * / Auxillary Method Library / * * * * * * * * * * * * * * * * * @\n",
    "# *                                                                                               * #\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "#@ * * * * * * * * * / Scraping The Latest Mars-Related News Article From NASA / * * * * * * * * * *@\n",
    "#@ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -@\n",
    "\n",
    "#@ C R I T I C A L   R E T U R N @\n",
    "def scrape_news(browser):\n",
    "    '''\n",
    "        scrape_news() first scrapes NASA's Mars website for all data in dividers of class type\n",
    "    \"content_title\". Next, the very first result, position [0], is casted to text and assigned the\n",
    "    variable called \"latest_title\".\n",
    "        Afterwards, the website is scraped for all data in dividers of class type\n",
    "    \"article_teaser_body\".\n",
    "        Again, the very first result, the most recent, is casted to text and assigned a variable\n",
    "    called \"latest_paragraph\". Last, both of the new variables are appended to a new dictionary\n",
    "    variable named \"latest_mars_news\" and then returned for later use.\n",
    "    '''\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    print('Fetching Latest News...\\n')\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    titles = soup.find_all('div', class_='content_title')\n",
    "    latest_title = titles[0].text\n",
    "    paragraphs = soup.find_all('div', class_='article_teaser_body')\n",
    "    latest_paragraph = paragraphs[0].text\n",
    "    latest_mars_news = {'title': latest_title,\n",
    "                        'paragraph': latest_paragraph}\n",
    "    return latest_mars_news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "#@ * * * * * * * / Scraping: The Currently Featured, Full-Sized Image Of Mars From JPL / * * * * *  @\n",
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "\n",
    "#@ C R I T I C A L   R E T U R N @\n",
    "def scrape_feature_image(browser):\n",
    "    '''\n",
    "        scrape_feature_image() starts attempting to have the variable \"image_data\" returned from the\n",
    "    nested function \"spaghetti\" (aptly named due to the spaghetti code this entire section is\n",
    "    comprised of). A TypeError is expected to return for the first attempt, but after triel and\n",
    "    error - a five second delay before retrying seems to do the trick.\n",
    "        Now with our data contained inside of \"image_data\" safe in hand, we are next able to pull\n",
    "    the image's full resolution source link out. We then assign it to its own variable as well\n",
    "    as a variable that has the full source location's url string which we then return for later\n",
    "    use.\n",
    "    '''\n",
    "    def spaghetti(browser):\n",
    "        '''\n",
    "            spaghetti lives up to its namesake in that I have no idea why it behaves the way it\n",
    "        does, but we've since formed a working relationship to accomplish our data analytics' goals.\n",
    "        Our first execution is expected to fail, so we just wait for scrape_feature_image() to try\n",
    "        again.\n",
    "            Now that that's done, we can get started by navigating the browser through the link\n",
    "        entitled \"FULL IMAGE\". Next we parse the html page we land on for only the first image tag\n",
    "        that is of class type \"fancybox-image\". We assign that raw html data to a variable and\n",
    "        return it back out to scrape_feature_image() for further use.\n",
    "        '''\n",
    "        url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "        browser.visit(url2)\n",
    "        html, soup = simmer_soup(browser)\n",
    "        browser.click_link_by_partial_text('FULL IMAGE')\n",
    "        html, soup = simmer_soup(browser)\n",
    "        image_data = soup.find('img', class_='fancybox-image')\n",
    "        return image_data\n",
    "    try:\n",
    "        image_data = spaghetti(browser)\n",
    "    except:\n",
    "        TypeError\n",
    "    print('Fetching Latest Featured Image...\\n')\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        image_data = spaghetti(browser)\n",
    "    except:\n",
    "        TypeError\n",
    "    featured_base = 'https://www.jpl.nasa.gov'\n",
    "    featured_end = image_data['src']\n",
    "    featured_image_url = featured_base + featured_end\n",
    "    return featured_image_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "#@ * * * / Scraping: The Latest Weather Report Via A Twitter Relay From The Curiosity Rover / * * * @\n",
    "#@ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "\n",
    "#@ C R I T I C A L   R E T U R N @\n",
    "def scrape_weather(browser):\n",
    "    '''\n",
    "        scrape_weather() navigates to the \"MarswxReport\" Twitter relay account to scrape the most\n",
    "    recent tweet sent directly from the REMS weather instrument aboard the Curiosity Rover!\n",
    "        The page's html is parsed and the most recent divider of class type\n",
    "    \"js-tweet-text-container\" is assigned the the variable \"tweet_data\". It is next chopped up so\n",
    "    that the photo link no longer remains amongst the Martian weather data and returned back out to\n",
    "    the main for later use.\n",
    "    '''\n",
    "    url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "    print('Fetching Latest Weather...\\n')\n",
    "    browser.visit(url3)\n",
    "    time.sleep(2)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    tweet_data = soup.find('div', class_='js-tweet-text-container')\n",
    "    mars_weather = tweet_data.text[1:-27]\n",
    "    return mars_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "#@* * * * * * / Scraping: A Table Of Mars-Centric Facts From An Space Enthusiasts Site / * * * * * *@\n",
    "#@ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "\n",
    "#@ C R I T I C A L   R E T U R N @\n",
    "def scrape_facts(browser):\n",
    "    '''\n",
    "        scrape_facts() was the most challenging part of the assignment for me. Without knowledge of\n",
    "    JS, I was unable to find any sort of method across the internet to dynamically convert my\n",
    "    DataFrame's \"to_html()\" data and then display its table string on an existing html document.\n",
    "        What I *did* find, was an old medium.com article written by an absent github user of the\n",
    "    last 3 years that went over and provided some very hacked together and incomplete incarnates of\n",
    "    imgkit and wkhtmltopdf. It all behaves strangely enough and throws bizarre enough errors while\n",
    "    in debug mode that I went on an \"Are these rootkits?\" adventure, but I digress.\n",
    "        Behold! The funkiest, most roundabout way of displaying the Martian facts' table data\n",
    "    scraped from the Space-Facts website.\n",
    "        We first read the raw html into a Series, where we next fix the ValueErrors to turn it into\n",
    "    a fully-fledged DataFrame. We immediately chuck it back out into an html table string where it\n",
    "    then goes to sit in a variable called \"mars_table_html_string\". It will be returned back to the\n",
    "    main, where it will eventually be locked up in my local MongoDB along with all the other pieces\n",
    "    of data.\n",
    "        Anyways, we next yeet out a .csv version of the Dataframe for good measure. Except we\n",
    "    actually will get some good use out of it! Next I shoved that very .csv right back into a new\n",
    "    DataFrame, wrote out a bunch of CSS styling that matches my current index html templates vibe.\n",
    "        ...We then embark on the aforementioned hack-job of python, pandas, css, html, subsystem\n",
    "    processes, IO writers and buffers, likely 0-day'd custom image munging modules, and sketchy,\n",
    "    Anti-Virus warning inducing .pkgs....until....we actually end up with a heckin' decent,\n",
    "    custom-sized, custom-quality-chosen, color-coordinating, .png of the original table we started\n",
    "    way back at the top of these paragraphs with.\n",
    "        I assign the output file's relative path into a variable and then send it off over to the\n",
    "    folder called \"static\" since that seems to be the only place that Flask will let me host pics on\n",
    "    my html pages from locally - As well as not output files into from a shell. If you try to run\n",
    "    this on your local system, get ready for a chmod party btw.\n",
    "        Last, we merge that mars_table_html_string along with the pretty .png picture of what the\n",
    "    html table string could only hope to someday be into a dictionary, and werf it back out to main.\n",
    "    '''\n",
    "    url4 = 'http://space-facts.com/mars/'\n",
    "    print('Fetching Latest Mars Facts...\\n')\n",
    "    browser.visit(url4)\n",
    "    time.sleep(2)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    mars_table = pd.read_html(html)\n",
    "    time.sleep(3)\n",
    "    mars_table = mars_table[(len(mars_table) - 1)]\n",
    "    mars_table_html_string = mars_table.to_html()\n",
    "    mars_table.to_csv('mars_facts.csv')\n",
    "    mars_table = pd.read_csv(open('mars_facts.csv', 'r'))\n",
    "    mars_css = \"\"\"\n",
    "    <style type=\\\"text/css\\\">\n",
    "    table {\n",
    "    color: #FFFFFF;\n",
    "    font-family: Helvetica, Arial, sans-serif;\n",
    "    width: 640px;\n",
    "    border-collapse:\n",
    "    collapse;\n",
    "    border-spacing: 0;\n",
    "    }\n",
    "    td, th {\n",
    "    border: 1px solid transparent; /* No more visible border */\n",
    "    height: 30px;\n",
    "    }\n",
    "    th {\n",
    "    background: #343A40; /* Darken header a bit */\n",
    "    color: #343A40;\n",
    "    font-weight: bold;\n",
    "    }\n",
    "    td {\n",
    "    background: #3D4449;\n",
    "    text-align: center;\n",
    "    }\n",
    "    table tr:nth-child(odd) td{\n",
    "    background-color: #343A40;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    print('Rendering Fact Table Image...\\n')\n",
    "    # TODO Deconstruct this nested func()\n",
    "    def DataFrame_to_image(data, css, outputfile=\"mars_facts.png\", format=\"png\"):\n",
    "        '''\n",
    "            I fully intend to deconstruct this to try and not have such a disgusting monstrosity of\n",
    "        a method for you to have to wretch at...but let's face it, prob not gonna happen. If you're \n",
    "        reading this I hope it has been amusing :)\n",
    "            Anywho this thing takes in a DataFrame, a CSS styles string literal, and then you just\n",
    "        pick out your output's filename and the format of it up there in the def line.\n",
    "            A solid 1/4 of this had broken code in it straight from the author, but, alas it moves\n",
    "        down the pipeline. It first makes up a temporary filename, and if a file already exists then\n",
    "        that existing one gets nerfed. That new temp file is opened and then the arguments supplied\n",
    "        are written into it. It's next shaken out into an html document, closed up, the .pngs\n",
    "        rendering options I chose are applied, the variable holding the name of the temporary file\n",
    "        is killed, and our glorious outputfile (just the filename) is returned out to scrape_facts()\n",
    "        for further data manipulation.\n",
    "        '''\n",
    "        fn = str(\"holding\" + \".html\")\n",
    "        try:\n",
    "            os.remove(fn)\n",
    "        except:\n",
    "            None\n",
    "        text_file = open(fn, \"a\")\n",
    "        text_file.write(css)\n",
    "        text_file.write(data.to_html())\n",
    "        text_file.close()\n",
    "        imgkitoptions = {\"width\": 652,\n",
    "                         'quality': 100}\n",
    "        imgkit.from_file(fn, outputfile, options=imgkitoptions)\n",
    "        os.remove(fn)\n",
    "        return outputfile\n",
    "    outputfile = DataFrame_to_image(mars_table, mars_css)\n",
    "    cwd = os.getcwd()\n",
    "    outputfilepath = str(cwd + '/' + outputfile)\n",
    "    subprocess.call('cp -rv mars_facts.png static/', shell=True)\n",
    "    mars_facts = {'html_string': mars_table_html_string,\n",
    "                  'table_image': outputfilepath}\n",
    "    return mars_facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "#@* * * * * * / Scraping: Descriptors + Photos Of Martian Hemispheres From The U.S.G.S / * * * * * *@\n",
    "#@ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - @\n",
    "\n",
    "#@ C R I T I C A L   R E T U R N @\n",
    "def scrape_hemispheres(browser):\n",
    "    '''\n",
    "    scrape_hemispheres() scrapes out the images as well as the descriptors thereof for each of The Red\n",
    "    Planet's hemispheres.\n",
    "    \"How?\", you might ask?\n",
    "    Well lemme tell you. The Splinter navigates onto the USGS' homebase where all link elements\n",
    "    (\"a\") of class typle \"itemLink\" are dumped into a variable assignment called \"links\". Now since\n",
    "    there were duplicate entries in our variable, we envoke a for-loop to append the distinct\n",
    "    entries (their href data specifically) into a new, blank list. Each distinct entry is assigned\n",
    "    out of the list and into another new variable as the \"end\" part of the full url src link. Next\n",
    "    I made the \"start\" or \"base\" url variable and linked them all up so we had the pages for each\n",
    "    Hemi.\n",
    "    We next go to each Hemi's page and dump the raw html data into \"Soups\" which we then pick out\n",
    "    the image and its descriptor, aptly named \"wide-image\" and \"title\" by our Federal compatriots.\n",
    "    Along the way, each of the Hemi's sets are appended into their own dicts, at the end all of\n",
    "    those dicts are appended to one big list of dicts called \"mars_hemisphere_list\" - I know, I'm\n",
    "    super creative -, which is then yonked back out to the main for further use.\n",
    "    '''\n",
    "    url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    print('\\nFetching Latest Hemisphere Images and Titles...')\n",
    "    browser.visit(url5)\n",
    "    time.sleep(2)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    links = soup.find_all('a', class_='itemLink')\n",
    "    links_list = []\n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        if href not in links_list:\n",
    "            links_list.append(href)\n",
    "    cerberus_end = links_list[0]\n",
    "    schiaparelli_end = links_list[1]\n",
    "    syrtis_major_end = links_list[2]\n",
    "    valles_marineris_end = links_list[3]\n",
    "    links_start = 'https://astrogeology.usgs.gov'\n",
    "    cerberus_full = links_start + cerberus_end\n",
    "    schiaperelli_full = links_start + schiaparelli_end\n",
    "    syrtis_major_full = links_start + syrtis_major_end\n",
    "    valles_marineris_full = links_start + valles_marineris_end\n",
    "    print('-----Cerberus...')\n",
    "    browser.visit(cerberus_full)\n",
    "    time.sleep(1)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    cerberus_pic_data = soup.find_all('img', class_=\"wide-image\")\n",
    "    cerberus_pic_end = cerberus_pic_data[0]['src']\n",
    "    cerberus_picture_full = links_start + cerberus_pic_end\n",
    "    cerberus_title_data = soup.find('h2', class_='title')\n",
    "    cerberus_title_full = cerberus_title_data.text\n",
    "    cerberus_dict = {'img_url': cerberus_picture_full,\n",
    "                     'title': cerberus_title_full}\n",
    "    print('-----Schiaperelli..')\n",
    "    browser.visit(schiaperelli_full)\n",
    "    time.sleep(1)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    schiaperelli_pic_data = soup.find_all('img', class_=\"wide-image\")\n",
    "    schiaperelli_pic_end = schiaperelli_pic_data[0]['src']\n",
    "    schiaperelli_picture_full = links_start + schiaperelli_pic_end\n",
    "    schiaperelli_title_data = soup.find('h2', class_='title')\n",
    "    schiaperelli_title_full = schiaperelli_title_data.text\n",
    "    schiaperelli_dict = {'img_url': schiaperelli_picture_full,\n",
    "                         'title': schiaperelli_title_full}\n",
    "    print('-----Syrtis Major...')\n",
    "    browser.visit(syrtis_major_full)\n",
    "    time.sleep(1)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    syrtis_major_pic_data = soup.find_all('img', class_=\"wide-image\")\n",
    "    syrtis_major_pic_end = syrtis_major_pic_data[0]['src']\n",
    "    syrtis_major_picture_full = links_start + syrtis_major_pic_end\n",
    "    syrtis_major_title_data = soup.find('h2', class_='title')\n",
    "    syrtis_major_title_full = syrtis_major_title_data.text\n",
    "    syrtis_major_dict = {'img_url': syrtis_major_picture_full,\n",
    "                         'title': syrtis_major_title_full}\n",
    "    print('-----Valles Marineris...\\n')\n",
    "    browser.visit(valles_marineris_full)\n",
    "    time.sleep(1)\n",
    "    html, soup = simmer_soup(browser)\n",
    "    valles_marineris_pic_data = soup.find_all('img', class_=\"wide-image\")\n",
    "    valles_marineris_pic_end = valles_marineris_pic_data[0]['src']\n",
    "    valles_marineris_picture_full = links_start + valles_marineris_pic_end\n",
    "    valles_marineris_title_data = soup.find('h2', class_='title')\n",
    "    valles_marineris_title_full = valles_marineris_title_data.text\n",
    "    valles_marineris_dict = {'img_url': valles_marineris_picture_full,\n",
    "                             'title': valles_marineris_title_full}\n",
    "    mars_hemisphere_list = []\n",
    "    mars_hemisphere_list.append(cerberus_dict)\n",
    "    mars_hemisphere_list.append(schiaperelli_dict)\n",
    "    mars_hemisphere_list.append(syrtis_major_dict)\n",
    "    mars_hemisphere_list.append(valles_marineris_dict)\n",
    "    return mars_hemisphere_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "# *                                                                                               * #\n",
    "#@* * * * * * * * * * * * / Test All of the Above Before Making the Biggun / * * * * * * * * * * * *@\n",
    "# *                                                                                               * #\n",
    "# * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * # * #\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#\n",
    "#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initizalizing Splinter Browser...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "browser = init_splinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Latest News...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Why This Martian Full Moon Looks Like Candy',\n",
       " 'paragraph': \"For the first time, NASA's Mars Odyssey orbiter has caught the Martian moon Phobos during a full moon phase. Each color in this new image represents a temperature range detected by Odyssey's infrared camera.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_mars_news = scrape_news(browser)\n",
    "latest_mars_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Latest Featured Image...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19048_ip.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_image_url = scrape_feature_image(browser)\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Latest Weather...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'InSight sol 162 (2019-05-12) low -100.2ºC (-148.3ºF) high -20.3ºC (-4.5ºF)\\nwinds from the SW at 4.5 m/s (10.1 mph) gusting to 14.3 m/s (32.0 mph)\\npressure at 7.50 hPa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_weather = scrape_weather(browser)\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Latest Mars Facts...\n",
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'html_string': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'table_image': '/Users/nicolespaar/Desktop/Scrape/mars_facts.png'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_facts = scrape_facts(browser)\n",
    "mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Latest Hemisphere Images and Titles...\n",
      "test\n",
      "-----Cerberus...\n",
      "-----Schiaperelli..\n",
      "-----Syrtis Major...\n",
      "-----Valles Marineris...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       "  'title': 'Cerberus Hemisphere Enhanced'},\n",
       " {'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       "  'title': 'Schiaparelli Hemisphere Enhanced'},\n",
       " {'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       "  'title': 'Syrtis Major Hemisphere Enhanced'},\n",
       " {'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg',\n",
       "  'title': 'Valles Marineris Hemisphere Enhanced'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_hemisphere_list = scrape_hemispheres(browser)\n",
    "mars_hemisphere_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initizalizing Splinter Browser...\n",
      "\n",
      "Fetching Latest News...\n",
      "\n",
      "Fetching Latest Featured Image...\n",
      "\n",
      "Fetching Latest Weather...\n",
      "\n",
      "Fetching Latest Mars Facts...\n",
      "\n",
      "Rendering Fact Table Image...\n",
      "\n",
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "\n",
      "Fetching Latest Hemisphere Images and Titles...\n",
      "-----Cerberus...\n",
      "-----Schiaperelli..\n",
      "-----Syrtis Major...\n",
      "-----Valles Marineris...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mars_hemisphere_list': [{'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       "   'title': 'Cerberus Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       "   'title': 'Schiaparelli Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       "   'title': 'Syrtis Major Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg',\n",
       "   'title': 'Valles Marineris Hemisphere Enhanced'}],\n",
       " 'latest_mars_news': {'title': 'Why This Martian Full Moon Looks Like Candy',\n",
       "  'paragraph': \"For the first time, NASA's Mars Odyssey orbiter has caught the Martian moon Phobos during a full moon phase. Each color in this new image represents a temperature range detected by Odyssey's infrared camera.\"},\n",
       " 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA18328_ip.jpg',\n",
       " 'latest_mars_weather': 'InSight sol 162 (2019-05-12) low -100.2ºC (-148.3ºF) high -20.3ºC (-4.5ºF)\\nwinds from the SW at 4.5 m/s (10.1 mph) gusting to 14.3 m/s (32.0 mph)\\npressure at 7.50 hPa',\n",
       " 'mars_facts': {'html_string': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       "  'table_image': '/Users/nicolespaar/Desktop/Scrape/mars_facts.png'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this one does it ALL except mongo\n",
    "def scrape_all_and_assemble(browser):\n",
    "    '''\n",
    "    scrape_all_and_assemble() does just that. It combines all of the newly refactored into single methods per\n",
    "    Query into one encompassing method. It even assembles all the data into one dictionary in preperation for\n",
    "    MongoDB to receive it as the next and current standing entry.\n",
    "    '''\n",
    "    browser.quit()\n",
    "    browser = init_splinter()\n",
    "    latest_mars_news = scrape_news(browser)\n",
    "    featured_image_url = scrape_feature_image(browser)\n",
    "    mars_weather = scrape_weather(browser)\n",
    "    mars_facts = scrape_facts(browser)\n",
    "    mars_hemisphere_list = scrape_hemispheres(browser)\n",
    "    browser.quit()\n",
    "    biggus_dictus = {'mars_hemisphere_list': mars_hemisphere_list,\n",
    "                                 'latest_mars_news': latest_mars_news,\n",
    "                                 'featured_image_url': featured_image_url,\n",
    "                                 'latest_mars_weather': mars_weather,\n",
    "                                 'mars_facts': mars_facts}\n",
    "    return biggus_dictus\n",
    "\n",
    "biggus_dictus = scrape_all_and_assemble(browser)\n",
    "biggus_dictus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ditching this notebook to wrap up the flask integration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
